{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5315145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in ./anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)   # Suppressing convergence warnings\n",
    "df = pd.read_csv('dataset.csv') # Loading and inspecting the dataset\n",
    "print(df.head())\n",
    "df['Result'] = df['Result'].map({-1: 0, 1: 1})\n",
    "X = df.drop(columns=['Result']) # Splitting the data into features (X) and target variable (y)\n",
    "y = df['Result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Splitting the dataset into training and testing sets\n",
    "xgb_classifier = XGBClassifier() # Initializing the XGBoost classifier\n",
    "xgb_classifier.fit(X_train, y_train)   # Training the classifier on the training data\n",
    "y_pred_train = xgb_classifier.predict(X_train)   # Making predictions on the training set\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)   # Calculating accuracy for the training set\n",
    "print(\"Accuracy with XGBoost on Training Set:\", accuracy_train)\n",
    "y_pred_test = xgb_classifier.predict(X_test)   # Making predictions on the testing set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)   # Calculating accuracy for the testing set\n",
    "print(\"Accuracy with XGBoost on Testing Set:\", accuracy_test)\n",
    "print(\"Classification Report:\")    # Additional evaluation metrics for the testing set\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "auc = roc_auc_score(y_test, y_pred_test)  # Calculating the Area under the ROC Curve\n",
    "print(\"Area under ROC Curve:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X = df.drop(columns=['Result'])    # Prepare features (X) and target variable (y)\n",
    "y = df['Result']\n",
    "bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)  # Initialize BaggingClassifier and perform cross-validation\n",
    "cv_bagging_decision_tree_scores = cross_val_score(bagging_classifier, X_train, y_train, cv=10, scoring='accuracy')\n",
    "print(\"Cross-Validation Scores with Bagging Decision Trees:\", cv_bagging_decision_tree_scores)\n",
    "print(\"Mean Accuracy of Bagging Decision Tree Classifier:\", cv_bagging_decision_tree_scores.mean()) \n",
    "bagging_classifier.fit(X_train, y_train)     # Train the classifier and make predictions on the test set \n",
    "y_pred_bagging = bagging_classifier.predict(X_test)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(\"Accuracy with Bagging Decision Trees on Testing Set:\", accuracy_bagging)\n",
    "print(\"Classification Report:\")  # Calculate additional metrics for the testing set\n",
    "print(classification_report(y_test, y_pred_bagging))\n",
    "auc = roc_auc_score(y_test, y_pred_bagging)\n",
    "print(\"Area under ROC Curve:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "weights_grid = {'weight_xgb': np.arange(0, 1.1, 0.1), 'weight_bagging': np.arange(0, 1.1, 0.1)}  # Define the grid for weights\n",
    "kf = KFold(n_splits=10, shuffle=True)               # Initialize KFold for cross-validation\n",
    "fusion_accuracies = []\n",
    "for weight_xgb in weights_grid['weight_xgb']:       # Perform interpolative fusion with cross-validation and weights \n",
    "    for weight_bagging in weights_grid['weight_bagging']:\n",
    "        total_weight = weight_xgb + weight_bagging  # Normalize the weights\n",
    "        if total_weight != 0:\n",
    "            weight_xgb_normalized = weight_xgb / total_weight\n",
    "            weight_bagging_normalized = weight_bagging / total_weight\n",
    "        else:\n",
    "            weight_xgb_normalized = 0\n",
    "            weight_bagging_normalized = 0\n",
    "        \n",
    "        fold_accuracies = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            xgb_classifier.fit(X_train, y_train)\n",
    "            bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "            xgb_pred = xgb_classifier.predict(X_test)\n",
    "            bagging_pred = bagging_classifier.predict(X_test)\n",
    "            fusion_pred = weight_xgb_normalized * xgb_pred + weight_bagging_normalized * bagging_pred   # Combine predictions using the normalized weights\n",
    "            fusion_pred_binary = np.where(fusion_pred > 0.5, 1, 0)\n",
    "            fold_accuracy = accuracy_score(y_test, fusion_pred_binary)\n",
    "            fold_accuracies.append(fold_accuracy)     # Calculate mean accuracy for this combination of weights\n",
    "        mean_accuracy = np.mean(fold_accuracies)\n",
    "        fusion_accuracies.append((mean_accuracy, {'weight_xgb': weight_xgb_normalized, 'weight_bagging': weight_bagging_normalized}))\n",
    "best_weights = max(fusion_accuracies, key=lambda x: x[0])[1]   # Select the best weights based on the highest mean accuracy\n",
    "print(\"Best Weights:\", best_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e592c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, roc_auc_score\n\u001b[0;32m----> 3\u001b[0m xgb_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)            \u001b[38;5;66;03m# Fit the classifiers using the best weights\u001b[39;00m\n\u001b[1;32m      4\u001b[0m bagging_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      5\u001b[0m xgb_pred_train \u001b[38;5;241m=\u001b[39m xgb_classifier\u001b[38;5;241m.\u001b[39mpredict(X_train) \u001b[38;5;66;03m# Predictions from each classifier on the training set\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    " \n",
    "xgb_classifier.fit(X_train, y_train)            # Fit the classifiers using the best weights\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "xgb_pred_train = xgb_classifier.predict(X_train) # Predictions from each classifier on the training set\n",
    "bagging_pred_train = bagging_classifier.predict(X_train)\n",
    "fusion_pred_train = best_weights['weight_xgb'] * xgb_pred_train + best_weights['weight_bagging'] * bagging_pred_train\n",
    "fusion_pred_binary_train = np.where(fusion_pred_train > 0.5, 1, 0)  # Combine the predictions using the best weights and calculate metrics on the training set\n",
    "precision_train = precision_score(y_train, fusion_pred_binary_train) # Calculate evaluation metrics on the training set\n",
    "recall_train = recall_score(y_train, fusion_pred_binary_train)\n",
    "f1_score_train = f1_score(y_train, fusion_pred_binary_train)\n",
    "roc_auc_train = roc_auc_score(y_train, fusion_pred_binary_train)\n",
    "print(\"Interpolative Fusion Metrics on Training Set with Best Weights:\")\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1-score:\", f1_score_train)\n",
    "print(\"Area under ROC curve:\", roc_auc_train)    # Predictions on the testing set and combine them using the best weights\n",
    "xgb_pred_test = xgb_classifier.predict(X_test)\n",
    "bagging_pred_test = bagging_classifier.predict(X_test)\n",
    "fusion_pred_test = best_weights['weight_xgb'] * xgb_pred_test + best_weights['weight_bagging'] * bagging_pred_test\n",
    "fusion_pred_binary_test = np.where(fusion_pred_test > 0.5, 1, 0)\n",
    "precision_test = precision_score(y_test, fusion_pred_binary_test) # Calculate evaluation metrics on the testing set\n",
    "recall_test = recall_score(y_test, fusion_pred_binary_test)\n",
    "f1_score_test = f1_score(y_test, fusion_pred_binary_test)\n",
    "roc_auc_test = roc_auc_score(y_test, fusion_pred_binary_test)\n",
    "print(\"\\nInterpolative Fusion Metrics on Testing Set with Best Weights:\")\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1-score:\", f1_score_test)\n",
    "print(\"Area under ROC curve:\", roc_auc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f61256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train_fusion = np.column_stack((X_train, fusion_pred_train))   # Concatenating the fusion predictions with the original dataset\n",
    "X_test_fusion = np.column_stack((X_test, fusion_pred_test))\n",
    "X_lr_train, X_lr_test, y_lr_train, y_lr_test = train_test_split(X_train_fusion, y_train, test_size=0.2, random_state=42) # Creating a train-test set for Linear regression\n",
    "linear_reg_fusion = LinearRegression()                           # Training a Linear Regression model and predictions on the training set\n",
    "linear_reg_fusion.fit(X_lr_train, y_lr_train)\n",
    "y_pred_linear_regression_train = linear_reg_fusion.predict(X_lr_train)\n",
    "y_pred_linear_regression_train_binary = np.where(y_pred_linear_regression_train > 0.5, 1, 0)  # Converting predictions to binary form\n",
    "linear_regression_accuracy_train = accuracy_score(y_lr_train, y_pred_linear_regression_train_binary)  # Calculating accuracy of the Linear Regression model on training data\n",
    "print(\"Accuracy of Linear Regression on Training Set with Interpolative Fusion Output:\", linear_regression_accuracy_train)\n",
    "precision_lr_train = precision_score(y_lr_train, y_pred_linear_regression_train_binary)   # Calculating precision, recall, F1-score, and area under ROC curve for Linear Regression\n",
    "recall_lr_train = recall_score(y_lr_train, y_pred_linear_regression_train_binary) \n",
    "f1_score_lr_train = f1_score(y_lr_train, y_pred_linear_regression_train_binary)\n",
    "roc_auc_lr_train = roc_auc_score(y_lr_train, y_pred_linear_regression_train)\n",
    "print(\"Linear Regression Metrics on Training Set with Interpolative Fusion Output:\")\n",
    "print(\"Precision:\", precision_lr_train)\n",
    "print(\"Recall:\", recall_lr_train)\n",
    "print(\"F1-score:\", f1_score_lr_train)\n",
    "print(\"Area under ROC curve:\", roc_auc_lr_train)\n",
    "y_pred_linear_regression_test = linear_reg_fusion.predict(X_lr_test) # Getting predictions from Linear Regression model on testing data\n",
    "y_pred_linear_regression_test_binary = np.where(y_pred_linear_regression_test > 0.5, 1, 0)  # Converting predictions to binary form\n",
    "linear_regression_accuracy_test = accuracy_score(y_lr_test, y_pred_linear_regression_test_binary) # Calculating accuracy of the Linear Regression model on the test set\n",
    "print(\"Accuracy of Linear Regression on Testing Set with Interpolative Fusion Output:\", linear_regression_accuracy_test)\n",
    "precision_lr_test = precision_score(y_lr_test, y_pred_linear_regression_test_binary)  # Calculating precision, recall, F1-score, and area under ROC curve for Linear Regression on testing set\n",
    "recall_lr_test = recall_score(y_lr_test, y_pred_linear_regression_test_binary)\n",
    "f1_score_lr_test = f1_score(y_lr_test, y_pred_linear_regression_test_binary)\n",
    "roc_auc_lr_test = roc_auc_score(y_lr_test, y_pred_linear_regression_test_binary)\n",
    "print(\"\\nLinear Regression Metrics on Testing Set with Interpolative Fusion Output:\")\n",
    "print(\"Precision:\", precision_lr_test)\n",
    "print(\"Recall:\", recall_lr_test)\n",
    "print(\"F1-score:\", f1_score_lr_test)\n",
    "print(\"Area under ROC curve:\", roc_auc_lr_test)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],             # Grid search for Random Forest hyperparameters\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_classifier_fusion = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_classifier_fusion, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_fusion, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "cv_scores = cross_val_score(best_rf_model, X_train_fusion, y_train, cv=5)  # Cross-validation scores of the best Random Forest model\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", np.mean(cv_scores))\n",
    "best_rf_model.fit(X_train_fusion, y_train)                       # Fitting best Random Forest model\n",
    "y_pred_rf_train_fusion = best_rf_model.predict(X_train_fusion)\n",
    "rf_accuracy_train_fusion = accuracy_score(y_train, y_pred_rf_train_fusion)  # Calculating accuracy of best Random Forest model on the training set\n",
    "print(\"Accuracy of Random Forest classifier on Training Set with Interpolative Fusion Output:\", rf_accuracy_train_fusion)\n",
    "precision_rf_train = precision_score(y_train, y_pred_rf_train_fusion)\n",
    "recall_rf_train = recall_score(y_train, y_pred_rf_train_fusion)    # Calculating precision, recall, F1-score, and area under ROC curve for Random Forest on training set\n",
    "f1_score_rf_train = f1_score(y_train, y_pred_rf_train_fusion)\n",
    "roc_auc_rf_train = roc_auc_score(y_train, y_pred_rf_train_fusion)\n",
    "print(\"Random Forest Metrics on Training Set with Interpolative Fusion Output:\")\n",
    "print(\"Precision:\", precision_rf_train)\n",
    "print(\"Recall:\", recall_rf_train)\n",
    "print(\"F1-score:\", f1_score_rf_train)\n",
    "print(\"Area under ROC curve:\", roc_auc_rf_train)\n",
    "y_pred_rf_test_fusion = best_rf_model.predict(X_test_fusion)   # Making predictions and calculating accuracy using best Random Forest model on the test set\n",
    "rf_accuracy_test_fusion = accuracy_score(y_test, y_pred_rf_test_fusion)\n",
    "print(\"Accuracy of Random Forest classifier on Testing Set with Interpolative Fusion Output:\", rf_accuracy_test_fusion)\n",
    "precision_rf_test = precision_score(y_test, y_pred_rf_test_fusion)  # Calculating precision, recall, F1-score, and area under ROC curve for Random Forest on testing set\n",
    "recall_rf_test = recall_score(y_test, y_pred_rf_test_fusion)\n",
    "f1_score_rf_test = f1_score(y_test, y_pred_rf_test_fusion)\n",
    "roc_auc_rf_test = roc_auc_score(y_test, y_pred_rf_test_fusion)\n",
    "print(\"\\nRandom Forest Metrics on Testing Set with Interpolative Fusion Output:\")\n",
    "print(\"Precision:\", precision_rf_test)\n",
    "print(\"Recall:\", recall_rf_test)\n",
    "print(\"F1-score:\", f1_score_rf_test)\n",
    "print(\"Area under ROC curve:\", roc_auc_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "linear_reg = LinearRegression()          \n",
    "linear_reg.fit(np.array(fusion_pred_train).reshape(-1, 1), y_train) # Train a Linear Regression model on the output from interpolative fusion\n",
    "continuous_output_train = linear_reg.predict(np.array(fusion_pred_train).reshape(-1, 1))  # Get the continuous output from the Linear Regression model for both training and testing sets\n",
    "continuous_output_test = linear_reg.predict(np.array(fusion_pred_test).reshape(-1, 1))\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)  # Train a Random Forest classifier on the output from interpolative fusion\n",
    "rf_classifier.fit(np.array(fusion_pred_train).reshape(-1, 1), y_train)\n",
    "y_pred_linear_regression_train = np.where(continuous_output_train > 0.5, 1, 0) # Make predictions using the Linear Regression model on the training and testing sets\n",
    "y_pred_linear_regression_test = np.where(continuous_output_test > 0.5, 1, 0)\n",
    "y_pred_rf_train = rf_classifier.predict(np.array(fusion_pred_train).reshape(-1, 1)) # Make predictions using the Random Forest classifier on the training and testing sets\n",
    "y_pred_rf_test = rf_classifier.predict(np.array(fusion_pred_test).reshape(-1, 1))\n",
    "X_train_stacking = np.column_stack((X_train, y_pred_linear_regression_train, y_pred_rf_train))  # Concatenate the predictions from both models with the original dataset\n",
    "X_test_stacking = np.column_stack((X_test, y_pred_linear_regression_test, y_pred_rf_test))\n",
    "log_reg_stacking = LogisticRegression()   # Train a logistic regression model on the concatenated features\n",
    "log_reg_stacking.fit(X_train_stacking, y_train)\n",
    "y_pred_stacking_test = log_reg_stacking.predict(X_test_stacking)  # Make predictions using the logistic regression model on the testing set\n",
    "stacking_accuracy_test = accuracy_score(y_test, y_pred_stacking_test) # Calculate accuracy of the logistic regression stacking model on the testing set\n",
    "print(\"Accuracy of Logistic Regression stacking model on Testing Set:\", stacking_accuracy_test)\n",
    "precision_stacking_test = precision_score(y_test, y_pred_stacking_test) # Calculate precision, recall, F1-score, and area under ROC curve for Logistic Regression stacking model\n",
    "recall_stacking_test = recall_score(y_test, y_pred_stacking_test)\n",
    "f1_score_stacking_test = f1_score(y_test, y_pred_stacking_test)\n",
    "roc_auc_stacking_test = roc_auc_score(y_test, y_pred_stacking_test)\n",
    "print(\"\\nLogistic Regression Stacking Metrics on Testing Set:\")\n",
    "print(\"Precision:\", precision_stacking_test)\n",
    "print(\"Recall:\", recall_stacking_test)\n",
    "print(\"F1-score:\", f1_score_stacking_test)\n",
    "print(\"Area under ROC curve:\", roc_auc_stacking_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
